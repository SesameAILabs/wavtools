export const StreamProcessorWorklet: "\n// StreamProcessor\n\nclass StreamProcessor extends AudioWorkletProcessor {\n  constructor() {\n    super();\n    this.hasStarted = false;\n    this.hasInterrupted = false;\n    this.outputBuffers = [];\n    this.bufferLength = 128;\n    this.write = { buffer: new Float32Array(this.bufferLength), trackId: null };\n    this.writeOffset = 0;\n\n    // configuration\n    this.playbackRateMin = 1;\n    this.playbackRateMax = 1;\n    this.playbackSmoothing = 0;\n    this.playbackSkipDigitalSilence = false;\n    this.playbackMinBuffers = 12; // 128 * 16 = 2048 samples @ 24kHz = 85ms (2 server frames)\n    \n    // state\n    this.playbackRate = 1;\n    this.playbackOutputOffset = 0;\n\n    this.isInPlayback = false;\n    this.trackSampleOffsets = {};\n    this.port.onmessage = (event) => {\n      if (event.data) {\n        const payload = event.data;\n        if (payload.event === 'write') {\n          const int16Array = payload.buffer;\n          const float32Array = new Float32Array(int16Array.length);\n          for (let i = 0; i < int16Array.length; i++) {\n            float32Array[i] = int16Array[i] / 0x8000; // Convert Int16 to Float32\n          }\n          this.writeData(float32Array, payload.trackId);\n        } else if (\n          payload.event === 'offset' ||\n          payload.event === 'interrupt'\n        ) {\n          const requestId = payload.requestId;\n          const trackId = this.write.trackId;\n          const offset = this.trackSampleOffsets[trackId] || 0;\n          this.port.postMessage({\n            event: 'offset',\n            requestId,\n            trackId,\n            offset,\n          });\n          if (payload.event === 'interrupt') {\n            this.hasInterrupted = true;\n          }\n        } else if (payload.event === 'configure') {\n          this.playbackMinBuffers = payload.playbackMinBuffers || this.playbackMinBuffers;\n          this.playbackRateMin = payload.playbackRateMin || this.playbackRateMin;\n          this.playbackRateMax = payload.playbackRateMax || this.playbackRateMax;\n          this.playbackSmoothing = payload.playbackSmoothing || this.playbackSmoothing;\n          this.playbackSkipDigitalSilence = payload.playbackSkipDigitalSilence || this.playbackSkipDigitalSilence;\n        } else {\n          throw new Error(`Unhandled event \"${payload.event}\"`);\n        }\n      }\n    };\n  }\n\n  writeData(float32Array, trackId = null) {\n    let { buffer } = this.write;\n    let offset = this.writeOffset;\n    for (let i = 0; i < float32Array.length; i++) {\n      buffer[offset++] = float32Array[i];\n      if (offset >= buffer.length) {\n        this.outputBuffers.push(this.write);\n        this.write = { buffer: new Float32Array(this.bufferLength), trackId };\n        buffer = this.write.buffer;\n        offset = 0;\n      }\n    }\n    this.writeOffset = offset;\n    return true;\n  }\n\n  process(inputs, outputs, parameters) {\n    const output = outputs[0];\n    const outputChannelData = output[0];\n    const outputBuffers = this.outputBuffers;\n\n    if (this.hasInterrupted) {\n      this.port.postMessage({ event: 'stop' });\n      return false;\n    } else {\n      let samplesMoved = 0;\n      let samplesWritten = 0\n\n      let outputBufferCount = outputBuffers.length;\n      \n      let iteration = 0;\n\n      while (outputBufferCount > 0) {\n        const outputChanneDataSampledNeeded = outputChannelData.length - samplesWritten;\n    \n        // apply playback rate to determine how many samples are needed\n        const playbackRate = this.setPlaybackRate();\n        const outputBufferSamplesNeeded = Math.floor(outputChanneDataSampledNeeded * playbackRate);\n        const outputBuffer = new Float32Array(outputBufferSamplesNeeded);\n\n        // get the next outputBufferSamplesNeeded samples from outputBuffers\n        let outputTrackId = null;\n\n        // read the necessary samples from the outputBuffers\n        let samplesRead = 0;\n        let outputBufferIndex = 0;\n        let outputBufferOffset = this.playbackOutputOffset;\n        for ( ; outputBufferIndex < outputBuffers.length; ++outputBufferIndex) {\n          const { buffer, trackId } = outputBuffers[outputBufferIndex];\n\n          for (let j = outputBufferOffset; j < buffer.length; ++j) {\n            outputBuffer[samplesRead++] = buffer[j];\n            \n            // advance output buffer\n            if (j === buffer.length - 1) {\n              outputBufferOffset = 0;\n            } else {\n              outputBufferOffset = j + 1;\n            }\n          }\n\n          outputTrackId = trackId;\n\n          // done if read enough samples\n          if (samplesRead === outputBufferSamplesNeeded) {\n            break;\n          }\n        }\n\n        // done if no samples read\n        if (samplesRead === 0) {\n          break;\n        }\n\n        this.hasStarted = true;\n\n        // apply playback rate to output buffer\n        let resampledBuffer = this.resampleAudioData(outputBuffer, outputChanneDataSampledNeeded);\n\n        // See if this resampledBuffer is digital silence. If it is, we skip it entirely.\n        let isDigitalSilence = true;\n        for (let i = 0; i < resampledBuffer.length; i++) {\n          if (resampledBuffer[i] !== 0) {\n            isDigitalSilence = false;\n            break;\n          }\n        }\n\n        // if not yet speaking (but have speech), still need to wait until enough input has been buffered\n        const consumeSilence = isDigitalSilence && this.playbackSkipDigitalSilence;\n        const consumePlayback = !isDigitalSilence && outputBufferCount >= this.playbackMinBuffers;\n\n        if (!this.isInPlayback && !consumeSilence && !consumePlayback) {\n          break;\n        }\n\n        // consume this buffer\n        samplesMoved += outputBuffer.length;\n\n        this.outputBuffers = outputBuffers.slice(outputBufferIndex);\n        this.playbackOutputOffset = outputBufferOffset;\n\n        // If it's not digital silence, we write.\n        if (!isDigitalSilence) {\n          for (let i = 0; i < resampledBuffer.length; ++i) {\n            outputChannelData[samplesWritten++] = resampledBuffer[i];\n          }\n        }\n\n        if (outputTrackId) {\n          this.trackSampleOffsets[outputTrackId] =\n            this.trackSampleOffsets[outputTrackId] || 0;\n          this.trackSampleOffsets[outputTrackId] += resampledBuffer.length;\n        }\n\n        // track buffer count before consuming\n        outputBufferCount = outputBuffers.length\n\n        // done if written enough samples\n        if (samplesWritten === outputChannelData.length) {\n          break;\n        }\n      }\n\n      if (samplesWritten > 0) {\n        this.isInPlayback = true;\n      } else {\n        this.isInPlayback = false;\n      }\n\n      // post audio playback timestamp\n      this.port.postMessage({\n        event: 'audio',\n        data: samplesMoved,\n        timestamp_ms: Date.now(),\n      });\n\n      return true;\n    }\n  }\n\n  // utility\n\n  resampleAudioData(float32Array, targetSamples) {\n    if (targetSamples === float32Array.length) {\n      return float32Array;\n    }\n    // Apply playback rate by resampling into a new buffer\n    const resampledBuffer = new Float32Array(targetSamples);\n    const playbackRate = float32Array.length / targetSamples;\n\n    for (let i = 0; i < targetSamples; ++i) {\n      const originalIndex = i * playbackRate;\n      const start = Math.floor(originalIndex);\n      const end = Math.ceil(originalIndex);\n\n      if (start === end || end >= float32Array.length) {\n        // If the start and end are the same or out of bounds, just use the start value\n        resampledBuffer[i] = float32Array[start];\n      } else {\n        // Linear interpolation between two samples\n        const ratio = originalIndex - start;\n        resampledBuffer[i] = float32Array[start] * (1 - ratio) + float32Array[end] * ratio;\n      }\n    }\n\n    // Apply a simple moving average to smooth the entire buffer\n    if (this.playbackSmoothing > 0) {\n      for (let i = 0; i < targetSamples; ++i) {\n        let sum = 0;\n        let count = 0;\n\n        // Sum over the window\n        for (let j = -smoothingWindow; j <= smoothingWindow; ++j) {\n          const idx = i + j;\n          if (idx >= 0 && idx < targetSamples) {\n            sum += resampledBuffer[idx];\n            count++;\n          }\n        }\n\n        // Calculate the average\n        resampledBuffer[i] = sum / count;\n      }\n    }\n\n    return resampledBuffer;\n  }\n\n  setPlaybackRate() {\n    let playbackRate = 1.0;\n    if (this.playbackRateMin < this.playbackRateMax && this.outputBuffers.length > 0) {\n      let totalAudioSamples = this.bufferLength * (this.outputBuffers.length - 1) + (this.bufferLength - this.playbackOutputOffset);\n\n      // audio buffer book-keeping - we want to buffer 2 server frames of audio\n      const serverSamplesTarget = this.playbackMinBuffers * this.bufferLength;\n      const serverSamplesDelta = totalAudioSamples - serverSamplesTarget\n\n      // only adjust playback rate if we are down to less than half our buffer\n      if (Math.abs(serverSamplesDelta) > 0.5 * serverSamplesTarget) {\n        if (serverSamplesDelta <= 0) {\n          // slow down\n          playbackRate = 1.0 + serverSamplesDelta / serverSamplesTarget;\n        } else {\n          // speed up\n          playbackRate = 1.0 / (1.0 - serverSamplesDelta / serverSamplesTarget);\n        }\n      }\n\n      playbackRate = this.playbackRate = Math.min(this.playbackRateMax, Math.max(this.playbackRateMin, playbackRate));\n    }\n    return playbackRate\n  }\n}\n\nregisterProcessor('stream_processor', StreamProcessor);\n";
export const StreamProcessorSrc: any;
//# sourceMappingURL=stream_processor.d.ts.map